<!doctype html><html lang=en-us>
<head>
<meta name=generator content="Hugo 0.91.2">
<meta charset=utf-8>
<meta name=viewport content="width=device-width,initial-scale=1">
<title>Home | Zhenyu Liao's Page</title>
<link rel=stylesheet href=/css/style.css>
<link rel=stylesheet href=/css/fonts.css>
</head>
<body>
<nav>
<ul class=menu>
<li><a href=/>Home</a></li>
<li><a href=/publications/>Publications</a></li>
<li><a href=/projects/>Projects</a></li>
<li><a href=/book/>Book</a></li>
<li><a href=/collaborators/>Collaborators</a></li>
<li><a href=/teaching/>Teaching</a></li>
<li><a href=/links/>Useful Links</a></li>
<li><a href=/index.xml>RSS subscribe</a></li>
</ul>
<hr>
</nav>
<img src=img/homepage.JPG style=max-width:20%;min-width:50px;float:right>
<h1 id=about-me>About Me</h1>
<p>I am now a tenure-track assistant professor at <a href=http://english.hust.edu.cn/>Huazhong University of Science & Technology (HUST)</a>, <a href=http://ei.hust.edu.cn/English/Home.htm>School of Electronic Information and Communications (EIC)</a>, where I&rsquo;m awarded the Wuhan Youth Talent and East Lake Youth Talent Fellowship 2021. Before that, I was a Postdoctoral Researcher at the University of California, Berkeley, <a href=https://statistics.berkeley.edu/>Department of Statistics</a> and <a href=https://www.icsi.berkeley.edu/icsi/>ICSI</a>, in 2020, hosted by Prof. <a href=https://www.stat.berkeley.edu/~mmahoney/>Michael Mahoney</a>. I received my Ph.D. from <a href=http://www.centralesupelec.fr/en>CentraleSupélec</a>, <a href=https://www.universite-paris-saclay.fr/en>University Paris-Saclay</a>, in 2019, where I worked under the supervision of Prof. <a href=http://romaincouillet.hebfree.org/>Romain Couillet</a> and Prof. <a href=https://www.researchgate.net/profile/Yacine_Chitour3>Yacine Chitour</a>. I received my B.Sc degree in <a href=http://english.oei.hust.edu.cn/>Optical and Electronic Information</a> from <a href=http://english.hust.edu.cn/>Huazhong University of Science & Technology</a>, China, in 2014, and my M.Sc. degree in Signal and Image Processing (<a href=http://www.master-atsi.universite-paris-saclay.fr/>ATSI</a>) from <a href=https://www.universite-paris-saclay.fr/en>University Paris-Saclay</a>, France, in 2016. My research interests are broadly in (statistical) machine learning, signal processing, random matrix theory, and high-dimensional statistics.</p>
<hr>
<h2 id=curriculum-vitae>Curriculum Vitae</h2>
<p>Here is my CV in <a href=/pdf/liao_CV.pdf>English</a> and in <a href=/pdf/Chines_cv_short.pdf>Chinese</a>.</p>
<p>My Erdős number is 4, via Romain Couillet, Zhidong Bai and Gutti Jogesh Babu.</p>
<hr>
<h2 id=news>News</h2>
<ul>
<li>I will be talking about some recent work on the interaction between RMT and machine learning at the SDS Workshop on &ldquo;Topics in Random Matrix Theory&rdquo; at CUHK-Shenzhen, see more details <a href=https://sds.cuhk.edu.cn/en/event/733>here</a>!</li>
<li>Happy to announce the 2022 Joint Workshop on &ldquo;Mathematics for Data Science&rdquo; between <a href=http://english.hust.edu.cn/>HUST</a> and <a href=https://www.universite-paris-saclay.fr/en>University Paris-Saclay</a> taking place in <strong>Sep 22-23 2022</strong> on zoom! Time: <em>9:00-12:00 Paris time</em> and <em>15:00-18:00 Beijing Time</em>. See the detailed schedule <a href=/pdf/HUST-UPSaclay_brochure_final.pdf>here</a> and the playabck <a href=https://www.bilibili.com/video/BV1G8411b7ir/>here (for Sep 22)</a> and <a href=https://www.bilibili.com/video/BV19e4y1k7VU>here (for Sep 23)</a>!</li>
<li>One paper at <strong>NeurIPS'2022</strong> on the eigenspectral structure of Neural Tangent Kernel (NTK) of fully-connected <em>Deep</em> neural networks for Gaussian mixture input data, with a compelling application to &ldquo;lossless&rdquo; sparsification and quantization of DNN models! This extends our <a href="https://openreview.net/forum?id=qwULHx9zld">previous paper</a> at <strong>ICLR'2022</strong>. See more details <a href="https://openreview.net/forum?id=NaW6T93F34m">here</a>.</li>
<li>Invited talk on &ldquo;Random Matrix Methods for Machine Learning: Lossless Compression of Large Neural Networks&rdquo; at <a href=https://c2sml.cn/conference_en.html>The China conference on Scientific Machine Learning (CSML 2022)</a>, see slides <a href=pdf/pre/talk_liao_NTK.pdf>here</a>.</li>
<li>Upcoming book &ldquo;<font color=red>Random Matrix Methods for Machine Learning</font>&rdquo; with Cambridge University Press, see more details <a href=https://www.cambridge.org/core/books/random-matrix-methods-for-machine-learning/6B681EB69E58B5F888EDB689C160C682>here</a>!</li>
<li>One paper at <strong>ICLR'2022</strong> on an incredibly efficient and theoretically guaranteed random feature compression technique, see more details <a href="https://openreview.net/forum?id=qwULHx9zld">here</a>.</li>
<li>One invited paper in <a href=https://iopscience.iop.org/journal/1742-5468/page/extraspecial19>Special Issue on Machine Learning 2021, JSTAT</a>, see more details <a href=https://iopscience.iop.org/article/10.1088/1742-5468/ac3a77>here</a>.</li>
<li>I&rsquo;m very grateful to be supported by the <font color=red>CCF-Hikvision Open Fund</font> on my research on the theory of neural network model compression (together with Dr. <a href="https://scholar.google.com/citations?user=EyzJHVsAAAAJ&hl=zh-CN">Kai Wan</a>), see more details <a href=https://www.ccf.org.cn/Collaboration/Enterprise_Fund/News/2021-10-22/746058.shtml>here</a>.</li>
<li>One <font color=red>oral</font> paper (top 1% submission) at <strong>NeurIPS'2021</strong> on the Hessian eigenspectra of generalized linear models, check our preprint <a href=https://arxiv.org/abs/2103.01519>here</a>!</li>
<li>One paper on &ldquo;Sparse sketches with small inversion bias&rdquo; accepted at <strong>COLT'2021</strong>, check our preprint <a href=https://arxiv.org/abs/2011.10695>here</a>!</li>
<li>Invited talk on &ldquo;A Data-dependent Theory of Overparameterization: Phase Transition, Double Descent, and Beyond&rdquo; at <a href=https://topml.rice.edu/>Workshop on the Theory of Over-parameterized Machine Learning (TOPML) 2021</a>. See <a href=pdf/pre/TOPML_talk_liao.pdf>slides</a>, <a href=pdf/pre/RFF_TOPML.pdf>two-page abstract</a>, and <a href=https://arxiv.org/abs/2006.05013>paper</a>.</li>
<li>One paper on &ldquo;kernel regression in high dimensions: refined analysis beyond double descent&rdquo; at <strong>AISTATS'2021</strong>! Check our preprint <a href=https://arxiv.org/abs/2010.02681>here</a>.</li>
<li>A <font color=red>spotlight</font> paper at <strong>ICLR'2021</strong> on computationally efficient (sparse and quantized) spectral clustering! Check <a href="https://openreview.net/forum?id=pBqLS-7KYAF">here</a>.</li>
</ul>
<p>For more information please refer to my detailed <a href=/pdf/liao_CV.pdf>CV</a>.</p>
<hr>
<h2 id=contact-me>Contact Me</h2>
<p><strong>E-mail</strong>: zhenyu_liao <strong>at</strong> hust.edu.cn, or click <a href=mailto:zhenyu_liao@hust.edu.cn>zhenyu_liao@hust.edu.cn</a></p>
<blockquote>
</blockquote>
<footer>
<script defer src=//zhenyu-liao.github.io/js/math-code.js></script>
<script defer src="//mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML"></script>
<script defer src=//zhenyu-liao.github.io/js/center-img.js></script>
<hr>
© <a href=https://zhenyu-liao.github.io/>Zhenyu Liao</a> 2016 &ndash; 2022 | <a href="https://scholar.google.fr/citations?user=SPYhJV8AAAAJ&hl=en">Google Scholar</a> | <a href=https://www.researchgate.net/profile/Zhenyu_Liao>Research Gate</a> | <a href=https://orcid.org/0000-0002-1915-8559>ORCID</a> | <a href=https://github.com/Zhenyu-LIAO/>Github</a> | <a href=https://zhuanlan.zhihu.com/RandomMatrixTheory>RMT on Zhihu</a>
</footer>
</body>
</html>