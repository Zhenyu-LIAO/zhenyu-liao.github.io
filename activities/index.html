<!doctype html><html lang=en-us><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><title>Activities | Zhenyu Liao's Page</title><link rel=stylesheet href=/css/style.css><link rel=stylesheet href=/css/fonts.css></head><body><nav><ul class=menu><li><a href=/>Home</a></li><li><a href=/publications/>Publications</a></li><li><a href=/activities/>Activities</a></li><li><a href=/index.xml>RSS subscribe</a></li></ul><hr></nav><div class=article-meta><h1><span class=title>Activities</span></h1></div><main><h2 id=talks>Talks</h2><ul><li>Invited talk on &ldquo;Performance-complexity Trade-off in Large Dimensional Spectral Clustering&rdquo; at <a href=https://rsfas.anu.edu.au/research/seminars/statistics-seminar-zhenyu-liao-uc-berkeley>Statistics Seminar</a>, Research School of Finance, Actuarial Studies and Statistics, Australian National University, Canberra, March, 2021.</li><li>Invited talk on &ldquo;Performance-complexity Trade-off in Large Dimensional Spectral Clustering&rdquo;, <a href=https://statistics.ucdavis.edu/events/seminar-012121-liao>STA 290 Seminar</a>, Department of Statistics, University of California, Davis, 2021.</li><li>Invited talk on &ldquo;Dynamical Aspects of Learning Linear Neural Networks&rdquo;, <a href=https://sites.google.com/site/boumedienehamzi/second-symposium-on-machine-learning-and-dynamical-systems>Second Symposium on Machine Learning and Dynamical Systems</a>, <a href=http://www.fields.utoronto.ca/>Fields Institute</a>, Toronto, September, 2020. See <a href=../pdf/pre/GDD_MLDS.pdf>slides</a> and <a href="https://www.youtube.com/watch?v=MCn7ze6Rvuc&t=802s">video</a>.</li><li>Invited talk on &ldquo;Random Matrix Advances in Large Dimensional Machine Learning&rdquo;, <a href=https://saasweb.hku.hk/workshop/rmcdaw2019/>Random Matrices and Complex Data Analysis Workshop</a>, <a href=http://english.sufe.edu.cn/>Shanghai University of Finance and Economics</a>, Shanghai, China, 10-12 December, 2019. See slides <a href=../pdf/pre/liao_SUFE_handout.pdf>here</a>.</li><li>Invited talk on &ldquo;RMT Viewpoint of Learning with Gradient Descent&rdquo;, <a href=http://dimacs.rutgers.edu/index.php/>DIMACS</a> workshop on <a href="http://dimacs.rutgers.edu/events/details?eID=316">Randomized Numerical Linear Algebra, Statistics, and Optimization</a>, Rutgers University, USA, 16-18 September, 2019. See <a href=../pdf/pre/DIMACS_liao_handout.pdf>slides</a> and <a href="https://www.youtube.com/watch?v=zKsrcGFiU3Y&t=3087s">video</a>.</li><li>Invited talk on &ldquo;Recent Advances in Random Matrix Theory for Machine Learning and Neural Nets&rdquo;, workshop of the <a href=http://cs.if.uj.edu.pl/matrix/>Matrix</a> series on &ldquo;Random matrix theory faces information era&rdquo;, Kraków, Poland, 29 April - 2 May, 2019. See <a href=../pdf/pre/Matrix_talk_liao_handout.pdf>slides</a> and <a href="https://www.youtube.com/watch?v=ZySvJRE2oLU&t=2557s">video</a>.</li><li>Invited talk on &ldquo;Dynamical Aspects of Deep Learning&rdquo; (with Y. Chitour), Séminaire d&rsquo;Automatique du plateau de Saclay of <a href=https://icode-seminars.github.io>iCODE</a>, Paris, France, 2019. See <a href=https://arxiv.org/abs/1811.03568>paper</a>, <a href=../pdf/pre/GDD_iCODE.pdf>slides</a>, and <a href="https://www.youtube.com/watch?v=JHzXHsCsQj4&t=4027s">video</a>.</li><li>Invited talk on &ldquo;Recent Advances in Random Matrix for Neural Networks&rdquo;, workshop on deep learning theory, Shanghai Jiao Tong University, China, 2018. See <a href=../pdf/pre/liao_SJTU_handout.pdf>slides</a>.</li><li>Tutorial on &ldquo;Random Matrix Advances in Machine Learning and Neural Nets&rdquo; (with R. Couillet and X. Mai), The 26th European Signal Processing Conference (<a href=http://www.eusipco2018.org/tutorials.php>EUSIPCO'18</a>), Roma, Italy, 2018. See <a href=../pdf/pre/tutorial_Eusipco_handout.pdf>slides</a> and more details <a href=../posts/eusipco18>here</a>.</li></ul><hr><h2 id=services>Services</h2><h3 id=editorial-board>Editorial Board</h3><ul><li>Signal Processing Theory (specialty section of <a href=https://www.frontiersin.org/journals/signal-processing#>Frontiers in Signal Processing</a>)</li></ul><h3 id=reviewing>Reviewing</h3><ul><li>AAAI Conference on Artificial Intelligence (AAAI)</li><li><a href=https://iclr.cc/>International Conference on Artificial Intelligence and Statistics (AISTATS)</a></li><li><a href=https://iclr.cc/>International Conference on Learning Representations (ICLR)</a></li><li><a href=https://icml.cc/>International Conference of Machine Learning (ICML)</a></li><li><a href=https://www.nserc-crsng.gc.ca/index_eng.asp>Natural Sciences and Engineering Research Council of Canada (NSERC)</a>, external reviewer</li><li><a href=https://nips.cc/>Neural Information Processing Systems (NeurIPS)</a></li><li><a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=34">IEEE Transaction on Pattern Analysis and Machine Intelligence (IEEE-TPAMI)</a></li><li><a href="http://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=78">IEEE Transactions on Signal Processing (IEEE-TSP)</a></li><li><a href=https://www.jmlr.org/>Journal of Machine Learning Research (JMLR)</a></li><li><a href=http://www.springer.com/computer/ai/journal/11063>Neural Processing Letters (NPL)</a></li><li><a href=https://www.journals.elsevier.com/pattern-recognition>Pattern Recognition (PR)</a></li><li><a href=https://journals.plos.org/plosone/>PLOS ONE</a></li><li><a href=https://www.worldscientific.com/worldscinet/rmta>Random Matrices: Theory and Applications (RMTA)</a></li></ul><hr><h2 id=teaching>Teaching</h2></main><footer><script src=//zhenyu-liao.github.io/js/math-code.js></script><script async src="//mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML"></script><script async src=//zhenyu-liao.github.io/js/center-img.js></script><hr>© <a href=https://zhenyu-liao.github.io/>Zhenyu Liao</a> 2016 &ndash; 2021 | <a href="https://scholar.google.fr/citations?user=SPYhJV8AAAAJ&hl=en">Google Scholar</a> | <a href=https://www.researchgate.net/profile/Zhenyu_Liao>Research Gate</a> | <a href=https://orcid.org/0000-0002-1915-8559>ORCID</a> | <a href=https://github.com/Zhenyu-LIAO/>Github</a> | <a href=https://zhuanlan.zhihu.com/RandomMatrixTheory>RMT on Zhihu</a></footer></body></html>