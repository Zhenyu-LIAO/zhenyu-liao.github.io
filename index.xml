<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Home on Zhenyu Liao's Page</title><link>https://zhenyu-liao.github.io/</link><description>Recent content in Home on Zhenyu Liao's Page</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Sat, 01 Sep 2018 00:00:00 +0000</lastBuildDate><atom:link href="https://zhenyu-liao.github.io/index.xml" rel="self" type="application/rss+xml"/><item><title>EUSIPCO'18 tutorial</title><link>https://zhenyu-liao.github.io/posts/eusipco18/</link><pubDate>Sat, 01 Sep 2018 00:00:00 +0000</pubDate><guid>https://zhenyu-liao.github.io/posts/eusipco18/</guid><description>I will be giving a tutorial at the 26th European Signal Processing Conference (EUSIPCO'18) in Rome, the Eternal City, Italy, together with my Ph.D. supervisor Prof. Romain Couillet and my colleague Xiaoyi Mai on the topic of &amp;ldquo;Random Matrix Advances in Machine Learning and Neural Nets&amp;rdquo;.
For more information please visit EUSIPCO'18.
Abstract
The advent of the Big Data era has triggered a renewed interest for machine learning and (deep) neural networks.</description></item><item><title>EUSIPCO'18 tutorial</title><link>https://zhenyu-liao.github.io/posts/gretsi17/</link><pubDate>Sat, 01 Sep 2018 00:00:00 +0000</pubDate><guid>https://zhenyu-liao.github.io/posts/gretsi17/</guid><description>I will be presenting our work about Random Feature Maps at Colloque GRETSI'17 this September at Juan Les Pins, France. The slides (in French) are available here.</description></item><item><title>EUSIPCO'18 tutorial</title><link>https://zhenyu-liao.github.io/posts/icassp17/</link><pubDate>Sat, 01 Sep 2018 00:00:00 +0000</pubDate><guid>https://zhenyu-liao.github.io/posts/icassp17/</guid><description>I will be presenting my work on LS-SVM at the 42nd IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP 2017), New Orleans, USA.
Here is the link to this four-paper conference paper. A extended journal version which contains all proof in detail is available here.
The slides presented on ICASSP 2017 are available here.</description></item><item><title>EUSIPCO'18 tutorial</title><link>https://zhenyu-liao.github.io/posts/icassp19/</link><pubDate>Sat, 01 Sep 2018 00:00:00 +0000</pubDate><guid>https://zhenyu-liao.github.io/posts/icassp19/</guid><description>My colleague Xiaoyi Mai will be presenting our paper on high dimensional logistic regression at ICASSP'19, 12-17 May, Brighton, UK.
The slides are available here.</description></item><item><title>EUSIPCO'18 tutorial</title><link>https://zhenyu-liao.github.io/posts/icml18/</link><pubDate>Sat, 01 Sep 2018 00:00:00 +0000</pubDate><guid>https://zhenyu-liao.github.io/posts/icml18/</guid><description>I will be presenting our works on Random Feature-based Clustering as well as Gradient Descent Dynamics at ICML 2018 this July, please find the two papers as follows:
[On the Spectrum of Random Features Maps of High Dimensional Data] and the slides here [The Dynamics of Learning: A Random Matrix Approach] and the slides here.</description></item><item><title>Ph.D. Mid-term</title><link>https://zhenyu-liao.github.io/posts/phd_mid/</link><pubDate>Sat, 01 Sep 2018 00:00:00 +0000</pubDate><guid>https://zhenyu-liao.github.io/posts/phd_mid/</guid><description>I&amp;rsquo;ve just finished my Ph.D. mid-term evaluation at CentraleSupelec. Here is the link of my mid-term report as well the slides.</description></item><item><title>Activities</title><link>https://zhenyu-liao.github.io/activities/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://zhenyu-liao.github.io/activities/</guid><description>Talks Invited talk on &amp;ldquo;A Data-dependent Theory of Overparameterization: Phase Transition, Double Descent, and Beyond&amp;rdquo; at Workshop on the Theory of Over-parameterized Machine Learning (TOPML) 2021, April 20-21, 2021. See slides, two-page abstract, and paper. Invited talk on &amp;ldquo;Performance-complexity Trade-off in Large Dimensional Spectral Clustering&amp;rdquo; at Statistics Seminar, Research School of Finance, Actuarial Studies and Statistics, Australian National University, Canberra, March 4, 2021. See slides here. Invited talk on &amp;ldquo;Performance-complexity Trade-off in Large Dimensional Spectral Clustering&amp;rdquo;, STA 290 Seminar, Department of Statistics, University of California, Davis, January 21, 2021.</description></item><item><title>Book</title><link>https://zhenyu-liao.github.io/book/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://zhenyu-liao.github.io/book/</guid><description>Random Matrix Methods for Machine Learning
By Romain Couillet and Zhenyu Liao
Book draft is available here and exercise solutions here. Expected publication data: October 2022.
Abstract Numerous and large dimensional data is now a default setting in modern machine learning (ML). Standard ML algorithms, starting with kernel methods such as support vector machines and graph-based methods like the PageRank algorithm, were however initially designed out of small dimensional intuitions and tend to misbehave, if not completely collapse, when dealing with real-world large datasets.</description></item><item><title>Publications</title><link>https://zhenyu-liao.github.io/publications/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://zhenyu-liao.github.io/publications/</guid><description>Conferences: Z. Liao, M. W. Mahoney, &amp;ldquo;Hessian Eigenspectra of More Realistic Nonlinear Models&amp;rdquo; (oral), The 35th Conference on Neural Information Processing Systems (NeurIPS'21), 2021. preprint
M. Derezi≈Ñski, Z. Liao, E. Dobriban, M. W. Mahoney, &amp;ldquo;Sparse sketches with small inversion bias&amp;rdquo;, The 34th Annual Conference on Learning Theory (COLT'2021), 2021. preprint
F. Liu, Z.Liao, J. A.K. Suykens, &amp;ldquo;Kernel regression in high dimension: Refined analysis beyond double descent&amp;rdquo;, The 24th International Conference on Artificial Intelligence and Statistics (AISTATS'2021), 2021.</description></item><item><title>Teaching</title><link>https://zhenyu-liao.github.io/teaching/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://zhenyu-liao.github.io/teaching/</guid><description>Teaching I am teaching &amp;ldquo;Deep Learning and Computer Vision&amp;rdquo; in the 2021 Fall semester, together with Prof. Xinggang Wang (https://xinggangw.info), below are the assignments/mini-projects aiming to improve your theoretical understanding and practical (coding) skills.
mini-project 1: training a linear model with gradient descent, see description here mini-project 2: training a single-hidden-layer neural network model, see description here mini-project 3: training a convolutional neural network, see description here mini-project 4: build your own MNIST-GAN, see description here</description></item></channel></rss>