<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Home on Zhenyu Liao's Page</title><link>https://zhenyu-liao.github.io/</link><description>Recent content in Home on Zhenyu Liao's Page</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Sat, 01 Sep 2018 00:00:00 +0000</lastBuildDate><atom:link href="https://zhenyu-liao.github.io/index.xml" rel="self" type="application/rss+xml"/><item><title>EUSIPCO'18 tutorial</title><link>https://zhenyu-liao.github.io/posts/archive/eusipco18/</link><pubDate>Sat, 01 Sep 2018 00:00:00 +0000</pubDate><guid>https://zhenyu-liao.github.io/posts/archive/eusipco18/</guid><description>I will be giving a tutorial at the 26th European Signal Processing Conference (EUSIPCO'18) in Rome, the Eternal City, Italy, together with my Ph.D. supervisor Prof. Romain Couillet and my colleague Xiaoyi Mai on the topic of &amp;ldquo;Random Matrix Advances in Machine Learning and Neural Nets&amp;rdquo;.
For more information please visit EUSIPCO'18.
Abstract
The advent of the Big Data era has triggered a renewed interest for machine learning and (deep) neural networks.</description></item><item><title>EUSIPCO'18 tutorial</title><link>https://zhenyu-liao.github.io/posts/archive/gretsi17/</link><pubDate>Sat, 01 Sep 2018 00:00:00 +0000</pubDate><guid>https://zhenyu-liao.github.io/posts/archive/gretsi17/</guid><description>I will be presenting our work about Random Feature Maps at Colloque GRETSI'17 this September at Juan Les Pins, France. The slides (in French) are available here.</description></item><item><title>EUSIPCO'18 tutorial</title><link>https://zhenyu-liao.github.io/posts/archive/icassp17/</link><pubDate>Sat, 01 Sep 2018 00:00:00 +0000</pubDate><guid>https://zhenyu-liao.github.io/posts/archive/icassp17/</guid><description>I will be presenting my work on LS-SVM at the 42nd IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP 2017), New Orleans, USA.
Here is the link to this four-paper conference paper. A extended journal version which contains all proof in detail is available here.
The slides presented on ICASSP 2017 are available here.</description></item><item><title>EUSIPCO'18 tutorial</title><link>https://zhenyu-liao.github.io/posts/archive/icassp19/</link><pubDate>Sat, 01 Sep 2018 00:00:00 +0000</pubDate><guid>https://zhenyu-liao.github.io/posts/archive/icassp19/</guid><description>My colleague Xiaoyi Mai will be presenting our paper on high dimensional logistic regression at ICASSP'19, 12-17 May, Brighton, UK.
The slides are available here.</description></item><item><title>EUSIPCO'18 tutorial</title><link>https://zhenyu-liao.github.io/posts/archive/icml18/</link><pubDate>Sat, 01 Sep 2018 00:00:00 +0000</pubDate><guid>https://zhenyu-liao.github.io/posts/archive/icml18/</guid><description>I will be presenting our works on Random Feature-based Clustering as well as Gradient Descent Dynamics at ICML 2018 this July, please find the two papers as follows:
[On the Spectrum of Random Features Maps of High Dimensional Data] and the slides here [The Dynamics of Learning: A Random Matrix Approach] and the slides here.</description></item><item><title>Ph.D. Mid-term</title><link>https://zhenyu-liao.github.io/posts/archive/phd_mid/</link><pubDate>Sat, 01 Sep 2018 00:00:00 +0000</pubDate><guid>https://zhenyu-liao.github.io/posts/archive/phd_mid/</guid><description>I&amp;rsquo;ve just finished my Ph.D. mid-term evaluation at CentraleSupelec. Here is the link of my mid-term report as well the slides.</description></item><item><title/><link>https://zhenyu-liao.github.io/posts/scientific_writing_checklist/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://zhenyu-liao.github.io/posts/scientific_writing_checklist/</guid><description>Checklist for scientific papers (before sending them to your supervisor) Feel free to drop me a line (at zhenyu_liao at hust.edu.cn) with your options and if you wish to add something to this list :)
Check the spelling Both with a spell-checker and by yourself! Logic and general Is the flow of logic clear from paragraph to paragraph? From your draft, you should be able to (re)write the outline of the paper.</description></item><item><title>Activities</title><link>https://zhenyu-liao.github.io/posts/archive/activities/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://zhenyu-liao.github.io/posts/archive/activities/</guid><description/></item><item><title>Book</title><link>https://zhenyu-liao.github.io/book/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://zhenyu-liao.github.io/book/</guid><description>Random Matrix Methods for Machine Learning Romain Couillet and Zhenyu Liao, Cambridge University Press, 2022.
Online Ordering: Cambridge University Press Amazon Additional Resources for Readers A pre-production version of the book is available here, with exercise solutions available here. MATLAB and Python codes to reproduce the figures in the book are publicly available in this repository.
Disclaimer: The pre-publication version is free to view and download for personal use only, and is not for redistribution, re-sale or use in derivative works.</description></item><item><title>Collaborators</title><link>https://zhenyu-liao.github.io/collaborators/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://zhenyu-liao.github.io/collaborators/</guid><description>I have been very fortunate to work with a number of great collaborators over the years.
Senior collaborators Prof. Romain Couillet: University Grenoble Alpes, Inria, CNRS, Grenoble INP, LIG, France. Holder of the UGA MIAI LargeDATA Chair. Prof. Michael Mahoney: Department of Statistics, International Computer Science Institute (ICSI), and Lawrence Berkeley National Laboratory (LBNL) at UC Berkeley, USA. Director of the UC Berkeley FODA (Foundations of Data Analysis) Institute grant.</description></item><item><title>Joint Workshop on "Math for Data Science"</title><link>https://zhenyu-liao.github.io/posts/workshop_math_data/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://zhenyu-liao.github.io/posts/workshop_math_data/</guid><description>Happy to announce the 2022 Joint Workshop on &amp;ldquo;Mathematics for Data Science&amp;rdquo; between HUST and University Paris-Saclay taking place in Sep 22-23 2022 on zoom! See the detailed program here and the playback here (for Sep 22) and here (for Sep 23)!
Time and Place: Sep 22-23 2022, Online, 9:00-12:00 Paris time and 15:00-18:00 Beijing Time.
Detailed program (Paris time):
Program for Thurs 22 Sep 2022 (Chair: Zhenyu Liao)
9:00&amp;ndash;9:10: Welcome speech, Robert C.</description></item><item><title>Posts</title><link>https://zhenyu-liao.github.io/post_page/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://zhenyu-liao.github.io/post_page/</guid><description> Checklist for scientific papers (before sending them to your supervisor)
Link to more details about short courses, tutorials, and invited talks
2022 Joint Workshop on &amp;ldquo;Mathematics for Data Science&amp;rdquo;&amp;quot; between HUST and University Paris-Saclay
Reading group on &amp;ldquo;Random Matrix Theory and Machine Learning&amp;rdquo;
Reading group on &amp;ldquo;Modern Deep Learning Theory and Practice&amp;rdquo;</description></item><item><title>Projects</title><link>https://zhenyu-liao.github.io/projects/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://zhenyu-liao.github.io/projects/</guid><description>NSFC-62206101: Fundamental Limits of Pruning Deep Neural Network Models via Random Matrix Methods This project (2023.01-2025.12) is led by myself, and focuses on the fundamental theoretical limits of pruning as well as quantization of deep neural networks. The objective of this project is to propose, by developing the mathematical tools of random matrix theory, high-dimensional statistics, and optimization theory, a quantitative theory to characterize the &amp;ldquo;performance and complexity tradeoff&amp;rdquo; in modern deep neural nets.</description></item><item><title>Publications</title><link>https://zhenyu-liao.github.io/publications/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://zhenyu-liao.github.io/publications/</guid><description>Conferences: J. Wei, X. Lee, Z. Liao, T. Palpanas, B. Peng &amp;ldquo;Subspace Collision: An Efficient and Accurate Framework for High-dimensional Approximate Nearest Neighbor Search,&amp;rdquo; SIGMOD International Conference on Management of Data (SIGMOD 2025), 2025.
L. Gu, Z. Liao &amp;ldquo;Beta-Companding: Simple and Efficient Non-uniform Quantization of DNNs without Backpropagation&amp;rdquo;, IEEE 34th International Workshop on Machine Learning for Signal Processing (MLSP 2024), 2024.
W. Yang, Z. Wang, X.</description></item><item><title>Reading group on Modern Deep Learning Theory and Practice</title><link>https://zhenyu-liao.github.io/posts/dl_theory_reading/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://zhenyu-liao.github.io/posts/dl_theory_reading/</guid><description>Schedule Date Speaker Papers to be presented 1 June 14, 2024 Yanlei Liu [D-9] 2 June 21, 2024 Chengmei Niu [D-8] 3 June 28, 2024 Jaiqing Liu [D-2] 4 July 05, 2024 Kexin Chen [D-10] 5 July 12, 2024 Muen Wu [D-5] 6 July 19, 2024 Yue Xu [D-4] List of papers [A] Tensor Program [][A-1] Yang, Greg.</description></item><item><title>Reading group on RMT and Machine Learning</title><link>https://zhenyu-liao.github.io/posts/rmt4ml_reading/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://zhenyu-liao.github.io/posts/rmt4ml_reading/</guid><description>Schedule Date Speaker Papers to be presented Dec. 27, 2023 Zhaorui Dong [B-1-1] Jan. 3, 2024 Zhuofan Xu [B-3-5] Jan. 10, 2024 Xuran Meng [C-2] Jan. 17, 2024 Jing Chen [F-1] Jan. 24, 2024 Xingkai Wen [B-3-6] Jan. 31, 2024 Tingting Zou [C-5] Feb. 7, 2024 Mengze Li [F-3] Feb.</description></item><item><title>Short courses, tutorials, and invited talks</title><link>https://zhenyu-liao.github.io/posts/talks/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://zhenyu-liao.github.io/posts/talks/</guid><description>Short courses 5H mini-course on &amp;ldquo;Random Matrix Theory for Machine Learning&amp;rdquo;, within thematic trimester on &amp;ldquo;Beyond classical regimes in statistical inference and machine learning&amp;rdquo; Centre International de Mathématiques et Informatique de Toulouse (CIMI), Toulouse, France, 2024. 12H mini-course on &amp;ldquo;Random Matrix Theory for Modern Machine Learning: New Intuitions, Improved Methods, and Beyond&amp;rdquo; at Institut de Recherche en Informatique de Toulouse (IRIT), Toulouse, France, July, 2024. See slides of Part 1, Part 2, Part 3, and Part 4.</description></item><item><title>Teaching</title><link>https://zhenyu-liao.github.io/teaching/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://zhenyu-liao.github.io/teaching/</guid><description>Undergraduate level Introduction to Machine Learning See an introductory lecture on machine learning here
Deep Learning and Computer Vision I am teaching the undergraduate level course &amp;ldquo;Deep Learning and Computer Vision&amp;rdquo; this 2021 Fall semester, together with Prof. Xinggang Wang (https://xinggangw.info), below are the assignments/mini-projects aiming to improve your theoretical understanding and practical (coding) skills.
mini-project 1: training a linear model with gradient descent, see description here mini-project 2: training a single-hidden-layer neural network model, see description here mini-project 3: training a convolutional neural network, see description here mini-project 4: build your own MNIST-GAN, see description here Graduate level Probability and Stochastic Processes II I am teaching the graduate (and Ph.</description></item><item><title>Useful Links</title><link>https://zhenyu-liao.github.io/links/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://zhenyu-liao.github.io/links/</guid><description>Research and Scientific Writing 现代科研指北 Advising Statement, by Marc F. Bellemare Learn LaTeX for LaTeX beginners and a short intro to LaTex (in Chinese) scientific writing for non-native speakers Linggle, Thesaurus, and DeepL Math WolframAlpha, Mathematics Stack Exchange, ProofWiki, and Matrix Calculus Math via visualization: 3Blue1Brown and Seeing Theory Blog of Terence Tao: What&amp;rsquo;s New Riemann 猜想漫谈 （by 卢昌海） Libres pensées d&amp;rsquo;un mathématicien ordinaire (by Djalil Chafaï) NIST Digital Library of Mathematical Functions AIM Approved Textbooks for freely available math textbooks Computer Science and AI NumPy for MATLAB user How To Start Open Source AI-research-tools (in Chinese) Visualization of Algorithms Awesome Machine Learning Resources Google Dataset Search ChatGPT for writing, and Prompt Library from University of Pennsylvania AI by Doing Gamma for presentation 科学空间 （by 苏剑林） Some (Personal) Resources 2-page appetizer of RMT for Signal Processing My research statement, Jan 2024.</description></item></channel></rss>