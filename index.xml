<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Home on Zhenyu Liao's Page</title><link>https://zhenyu-liao.github.io/</link><description>Recent content in Home on Zhenyu Liao's Page</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Sat, 01 Sep 2018 00:00:00 +0000</lastBuildDate><atom:link href="https://zhenyu-liao.github.io/index.xml" rel="self" type="application/rss+xml"/><item><title>EUSIPCO'18 tutorial</title><link>https://zhenyu-liao.github.io/posts/archive/eusipco18/</link><pubDate>Sat, 01 Sep 2018 00:00:00 +0000</pubDate><guid>https://zhenyu-liao.github.io/posts/archive/eusipco18/</guid><description>I will be giving a tutorial at the 26th European Signal Processing Conference (EUSIPCO'18) in Rome, the Eternal City, Italy, together with my Ph.D. supervisor Prof. Romain Couillet and my colleague Xiaoyi Mai on the topic of &amp;ldquo;Random Matrix Advances in Machine Learning and Neural Nets&amp;rdquo;.
For more information please visit EUSIPCO'18.
Abstract
The advent of the Big Data era has triggered a renewed interest for machine learning and (deep) neural networks.</description></item><item><title>EUSIPCO'18 tutorial</title><link>https://zhenyu-liao.github.io/posts/archive/gretsi17/</link><pubDate>Sat, 01 Sep 2018 00:00:00 +0000</pubDate><guid>https://zhenyu-liao.github.io/posts/archive/gretsi17/</guid><description>I will be presenting our work about Random Feature Maps at Colloque GRETSI'17 this September at Juan Les Pins, France. The slides (in French) are available here.</description></item><item><title>EUSIPCO'18 tutorial</title><link>https://zhenyu-liao.github.io/posts/archive/icassp17/</link><pubDate>Sat, 01 Sep 2018 00:00:00 +0000</pubDate><guid>https://zhenyu-liao.github.io/posts/archive/icassp17/</guid><description>I will be presenting my work on LS-SVM at the 42nd IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP 2017), New Orleans, USA.
Here is the link to this four-paper conference paper. A extended journal version which contains all proof in detail is available here.
The slides presented on ICASSP 2017 are available here.</description></item><item><title>EUSIPCO'18 tutorial</title><link>https://zhenyu-liao.github.io/posts/archive/icassp19/</link><pubDate>Sat, 01 Sep 2018 00:00:00 +0000</pubDate><guid>https://zhenyu-liao.github.io/posts/archive/icassp19/</guid><description>My colleague Xiaoyi Mai will be presenting our paper on high dimensional logistic regression at ICASSP'19, 12-17 May, Brighton, UK.
The slides are available here.</description></item><item><title>EUSIPCO'18 tutorial</title><link>https://zhenyu-liao.github.io/posts/archive/icml18/</link><pubDate>Sat, 01 Sep 2018 00:00:00 +0000</pubDate><guid>https://zhenyu-liao.github.io/posts/archive/icml18/</guid><description>I will be presenting our works on Random Feature-based Clustering as well as Gradient Descent Dynamics at ICML 2018 this July, please find the two papers as follows:
[On the Spectrum of Random Features Maps of High Dimensional Data] and the slides here [The Dynamics of Learning: A Random Matrix Approach] and the slides here.</description></item><item><title>Ph.D. Mid-term</title><link>https://zhenyu-liao.github.io/posts/archive/phd_mid/</link><pubDate>Sat, 01 Sep 2018 00:00:00 +0000</pubDate><guid>https://zhenyu-liao.github.io/posts/archive/phd_mid/</guid><description>I&amp;rsquo;ve just finished my Ph.D. mid-term evaluation at CentraleSupelec. Here is the link of my mid-term report as well the slides.</description></item><item><title/><link>https://zhenyu-liao.github.io/posts/scientific_writing_checklist/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://zhenyu-liao.github.io/posts/scientific_writing_checklist/</guid><description>Checklist for scientific papers (before sending them to your supervisor) Feel free to drop me a line (at zhenyu_liao at hust.edu.cn) with your options and if you wish to add something to this list :)
Check the spelling Both with a spell-checker and by yourself! Logic and general Is the flow of logic clear from paragraph to paragraph? From your draft, you should be able to (re)write the outline of the paper.</description></item><item><title>Activities</title><link>https://zhenyu-liao.github.io/posts/archive/activities/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://zhenyu-liao.github.io/posts/archive/activities/</guid><description/></item><item><title>Book</title><link>https://zhenyu-liao.github.io/book/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://zhenyu-liao.github.io/book/</guid><description>Random Matrix Methods for Machine Learning Romain Couillet and Zhenyu Liao, Cambridge University Press, 2022.
Online Ordering: Cambridge University Press Amazon Additional Resources for Readers A pre-production version of the book is available here, with exercise solutions available here. MATLAB and Python codes to reproduce the figures in the book are publicly available in this repository.
Disclaimer: The pre-publication version is free to view and download for personal use only, and is not for redistribution, re-sale or use in derivative works.</description></item><item><title>Collaborators</title><link>https://zhenyu-liao.github.io/collaborators/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://zhenyu-liao.github.io/collaborators/</guid><description>I have been very fortunate to work with a number of great collaborators over the years.
Senior collaborators Prof. Romain Couillet: University Grenoble Alpes, Inria, CNRS, Grenoble INP, LIG, France. Holder of the UGA MIAI LargeDATA Chair. Prof. Michael Mahoney: Department of Statistics, International Computer Science Institute (ICSI), and Lawrence Berkeley National Laboratory (LBNL) at UC Berkeley, USA. Director of the UC Berkeley FODA (Foundations of Data Analysis) Institute grant.</description></item><item><title>Joint Workshop on "Math for Data Science"</title><link>https://zhenyu-liao.github.io/posts/workshop_math_data/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://zhenyu-liao.github.io/posts/workshop_math_data/</guid><description>Happy to announce the 2022 Joint Workshop on &amp;ldquo;Mathematics for Data Science&amp;rdquo; between HUST and University Paris-Saclay taking place in Sep 22-23 2022 on zoom! See the detailed program here and the playback here (for Sep 22) and here (for Sep 23)!
Time and Place: Sep 22-23 2022, Online, 9:00-12:00 Paris time and 15:00-18:00 Beijing Time.
Detailed program (Paris time):
Program for Thurs 22 Sep 2022 (Chair: Zhenyu Liao)
9:00&amp;ndash;9:10: Welcome speech, Robert C.</description></item><item><title>Posts</title><link>https://zhenyu-liao.github.io/post_page/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://zhenyu-liao.github.io/post_page/</guid><description> Checklist for scientific papers (before sending them to your supervisor)
Link to more details about short courses, tutorials, and invited talks
2022 Joint Workshop on &amp;ldquo;Mathematics for Data Science&amp;rdquo;&amp;quot; between HUST and University Paris-Saclay
Reading group on &amp;ldquo;Random Matrix Theory and Machine Learning&amp;rdquo;
Reading group on &amp;ldquo;Modern Deep Learning Theory and Practice&amp;rdquo;
A list of RMTA activities</description></item><item><title>Projects</title><link>https://zhenyu-liao.github.io/projects/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://zhenyu-liao.github.io/projects/</guid><description>Ongoing NSFC-62206101: Fundamental Limits of Pruning Deep Neural Network Models via Random Matrix Methods This project (2023.01–2025.12), led by myself, investigates the fundamental theoretical limits of pruning and quantization in deep neural networks. The main objective is to develop a quantitative theoretical framework—grounded in random matrix theory, high-dimensional statistics, and optimization theory—to rigorously characterize the trade-off between model performance and computational complexity in modern deep neural architectures.
The project has resulted in the following scientific publications:</description></item><item><title>Publications</title><link>https://zhenyu-liao.github.io/publications/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://zhenyu-liao.github.io/publications/</guid><description>Conferences: C. Niu, Z. Liao, Z. Ling, M. W. Mahoney, &amp;ldquo;Fundamental Bias in Inverting Random Sampling Matrices with Application to Sub-sampled Newton&amp;rdquo; (Spotlight), The Forty-Second International Conference on Machine Learning (ICML 2025), 2025. preprint
X. Mai, Z. Liao, &amp;ldquo;The Breakdown of Gaussian Universality in Classification of High-dimensional Mixtures&amp;rdquo;, The Thirteenth International Conference on Learning Representations (ICLR 2025), 2025. preprint and slides
J. Wei, X. Lee, Z.</description></item><item><title>Reading group on Modern Deep Learning Theory and Practice</title><link>https://zhenyu-liao.github.io/posts/dl_theory_reading/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://zhenyu-liao.github.io/posts/dl_theory_reading/</guid><description>Schedule Date Speaker Papers to be presented 1 June 14, 2024 Yanlei Liu [D-9] 2 June 21, 2024 Chengmei Niu [D-8] 3 June 28, 2024 Jaiqing Liu [D-2] 4 July 05, 2024 Kexin Chen [D-10] 5 July 12, 2024 Muen Wu [D-5] 6 July 19, 2024 Yue Xu [D-4] List of papers [A] Tensor Program [][A-1] Yang, Greg.</description></item><item><title>Reading group on RMT and Machine Learning</title><link>https://zhenyu-liao.github.io/posts/rmt4ml_reading/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://zhenyu-liao.github.io/posts/rmt4ml_reading/</guid><description>Schedule Date Speaker Papers to be presented Dec. 27, 2023 Zhaorui Dong [B-1-1] Jan. 3, 2024 Zhuofan Xu [B-3-5] Jan. 10, 2024 Xuran Meng [C-2] Jan. 17, 2024 Jing Chen [F-1] Jan. 24, 2024 Xingkai Wen [B-3-6] Jan. 31, 2024 Tingting Zou [C-5] Feb. 7, 2024 Mengze Li [F-3] Feb.</description></item><item><title>RMTA activities</title><link>https://zhenyu-liao.github.io/posts/rmta_activities/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://zhenyu-liao.github.io/posts/rmta_activities/</guid><description>Online Seminar and/or Working Groups CNRS GDR MEGA, France: https://www.ceremade.dauphine.fr/dokuwiki/mega:start Random Matrix Theory Seminars, Mathematical Institute, Oxford University: https://www.maths.ox.ac.uk/events/list/3669 RMTA China Online Seminar: visit the seminar page of more information, and feel free to follow the RMTA seminar Google group! Workshops and Conferences: 2025 Date Place Name Link Feb 24–28, 2025 IPAM, UCLA, Los Angeles, USA Free Entropy Theory and Random Matrices Link May 12–16, 2025 KIAS, Seoul, Korea Universality, Nonlinearity, and Integrability (conference in honor of Percy Deift’s 80th birthday) Link June 2–6, 2025 ENS de Lyon, France Integrability, Random Matrices, and All That Link June 16–20, 2025 University of Washington, Seattle, USA The Second Conference on Random Matrix Theory and Numerical Linear Algebra Link June 16–20, 2025 Rényi Institute, Budapest, Hungary School on Stochastic Interacting Particle Systems and Random Matrices Link June 23–27, 2025 Rényi Institute, Budapest, Hungary Workshop on Stochastic Interacting Particle Systems and Random Matrices Link July 7–11, 2025 Université d&amp;rsquo;Angers, Angers, France InterPlay between Integrable Probability and Interacting Particle Systems ((IP)³) Link Aug 4–15, 2025 MATRIX Institute, Creswick, Australia Log-gases in Caeli Australi: Recent Developments in and around Random Matrix Theory Link Aug–Dec 2025 ZiF, University of Bielefeld, Germany The Lush World of Random Matrices Link Aug 25-Sep 6 ZIF, University of Bielefeld, Germany Fifth ZiF Summer School Randomness in Physics and Mathematics: From Thermalisation in Quantum Systems to Random Matrices Link Sep 8–12, 2025 Department of Mathematics, Kyoto University, Japan Random Matrix Theory Summer School in Japan 2025 Link Oct 9, 2025 Central America Room, ISI WSC 2025, The Hague, Netherlands IPS 705 - Random Matrix Theory: Recent Advances in Theory and Application Link 2026 Date Place Name Link Contact Please feel free to drop me a line at zhenyu_liao at hust.</description></item><item><title>Short courses, tutorials, and invited talks</title><link>https://zhenyu-liao.github.io/posts/talks/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://zhenyu-liao.github.io/posts/talks/</guid><description>Short courses 5H mini-course on &amp;ldquo;Random Matrix Theory for Machine Learning&amp;rdquo;, within thematic trimester on &amp;ldquo;Beyond classical regimes in statistical inference and machine learning&amp;rdquo; Centre International de Mathématiques et Informatique de Toulouse (CIMI), Toulouse, France, 2024. See slides here: Part 1 and Part 2. 12H mini-course on &amp;ldquo;Random Matrix Theory for Modern Machine Learning: New Intuitions, Improved Methods, and Beyond&amp;rdquo; at Institut de Recherche en Informatique de Toulouse (IRIT), Toulouse, France, July, 2024.</description></item><item><title>Teaching</title><link>https://zhenyu-liao.github.io/teaching/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://zhenyu-liao.github.io/teaching/</guid><description>Undergraduate level 随机过程 我从2025-2026学年开始讲授本科课程“随机过程”，课件如下。
0 概率论预备知识 1 随机过程基本概念 Introduction to Machine Learning See an introductory lecture on machine learning here
Deep Learning and Computer Vision I am teaching the undergraduate level course &amp;ldquo;Deep Learning and Computer Vision&amp;rdquo; this 2021 Fall semester, together with Prof. Xinggang Wang (https://xinggangw.info), below are the assignments/mini-projects aiming to improve your theoretical understanding and practical (coding) skills.
mini-project 1: training a linear model with gradient descent, see description here mini-project 2: training a single-hidden-layer neural network model, see description here mini-project 3: training a convolutional neural network, see description here mini-project 4: build your own MNIST-GAN, see description here Graduate level Probability and Stochastic Processes II I am teaching the graduate (and Ph.</description></item><item><title>Useful Links</title><link>https://zhenyu-liao.github.io/links/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://zhenyu-liao.github.io/links/</guid><description>Research and Scientific Writing 现代科研指北 Advising Statement, by Marc F. Bellemare Learn LaTeX for LaTeX beginners and a short intro to LaTex (in Chinese) Math WolframAlpha, Mathematics Stack Exchange, ProofWiki, and Matrix Calculus Math via visualization: 3Blue1Brown, Seeing Theory, 看见概率论 Blog of Terence Tao: What&amp;rsquo;s New Riemann 猜想漫谈 （by 卢昌海） Libres pensées d&amp;rsquo;un mathématicien ordinaire (by Djalil Chafaï) NIST Digital Library of Mathematical Functions AIM Approved Textbooks for freely available math textbooks Probability and Measure by Patrick Billingsley.</description></item></channel></rss>