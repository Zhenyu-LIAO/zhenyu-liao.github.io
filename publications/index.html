<!doctype html><html lang=en-us>
<head>
<meta charset=utf-8>
<meta name=viewport content="width=device-width,initial-scale=1">
<title>Publications | Zhenyu Liao's Page</title>
<link rel=stylesheet href=/css/style.css>
<link rel=stylesheet href=/css/fonts.css>
</head>
<body>
<nav>
<ul class=menu>
<li><a href=/>Home</a></li>
<li><a href=/publications/>Publications</a></li>
<li><a href=/projects/>Projects</a></li>
<li><a href=/book/>Book</a></li>
<li><a href=/collaborators/>Collaborators</a></li>
<li><a href=/teaching/>Teaching</a></li>
<li><a href=/links/>Links</a></li>
<li><a href=/post_page/>Posts</a></li>
<li><a href=/index.xml>RSS subscribe</a></li>
</ul>
<hr>
</nav>
<div class=article-meta>
<h1><span class=title>Publications</span></h1>
</div>
<main>
<h3 id=conferences>Conferences:</h3>
<ol>
<li>
<p>J. Wei, X. Lee, <strong>Z. Liao</strong>, T. Palpanas, B. Peng &ldquo;<a href>Subspace Collision: An Efficient and Accurate Framework for High-dimensional Approximate Nearest Neighbor Search</a>&rdquo;, <em>SIGMOD International Conference on Management of Data (<strong>SIGMOD 2025</strong>)</em>, 2025. <a href=https://arxiv.org/abs/2411.14754>preprint</a></p>
</li>
<li>
<p>W. Yang, Z. Wang, X. Mai, Z. Ling, R. C. Qiu, <strong>Z. Liao</strong> &ldquo;<a href=https://ieeexplore.ieee.org/document/10715081/>Inconsistency of ESPRIT DoA Estimation for Large Arrays and a Correction via RMT</a>&rdquo; (<font color=red>Best Student Paper Candidate</font>), <em>IEEE 32nd European Signal Processing Conference (<strong>EUSIPCO 2024</strong>)</em>, 2024.</p>
</li>
<li>
<p>Z. Ling, L. Li, Z. Feng, Y. Zhang, F. Zhou, R. C. Qiu, <strong>Z. Liao</strong> &ldquo;<a href=https://proceedings.mlr.press/v235/ling24a.html>Deep Equilibrium Models are Almost Equivalent to Not-so-deep Explicit Models for High-dimensional Gaussian Mixtures</a>&rdquo;, <em>The Forty-first International Conference on Machine Learning (<strong>ICML 2024</strong>)</em>, 2024. <a href=https://arxiv.org/abs/2402.02697>preprint</a></p>
</li>
<li>
<p>Y. Song, K. Wan, <strong>Z. Liao</strong>, H. Xu, G. Caire, S. Shamai, &ldquo;<a href=https://ieeexplore.ieee.org/document/10619077>An Achievable and Analytic Solution to Information Bottleneck for Gaussian Mixtures</a>&rdquo;, <em>2024 IEEE International Symposium on Information Theory (<strong>ISIT 2024</strong>)</em>, 2024.</p>
</li>
<li>
<p>Y. Wang, Z. Feng, <strong>Z. Liao</strong>, &ldquo;<a href=https://ieeexplore.ieee.org/document/10626024>FedRF-Adapt: Robust and Communication-Efficient Federated Domain Adaptation via Random Features</a>&rdquo;, <em><a href=https://workshop-tpmln2024.webflow.io/>Workshop on Timely and Private Machine Learning over Networks</a></em>, <em>2024 IEEE International Conference on Acoustics, Speech and Signal Processing (<strong>ICASSPW 2024</strong>)</em>, 2024.</p>
</li>
<li>
<p>L. Gu, Y. Du, Y. Zhang, D. Xie, S. Pu, R. C. Qiu, <strong>Z. Liao</strong>, &ldquo;<a href=https://proceedings.neurips.cc/paper_files/paper/2022/hash/185087ea328b4f03ea8fd0c8aa96f747-Abstract-Conference.html>&ldquo;Lossless&rdquo; Compression of Deep Neural Networks: A High-dimensional Neural Tangent Kernel Approach</a>&rdquo; (<font color=red>Spotlight</font>), <em>The 36th Conference on Neural Information Processing Systems (<strong>NeurIPS 2022</strong>)</em>, 2022. <a href=https://arxiv.org/abs/2403.00258>preprint</a> by fixing typos in Theorems 1 and 2 from the NeurIPS 2022 proceeding version.</p>
</li>
<li>
<p>H. Tiomoko, <strong>Z. Liao</strong>, R. Couillet, &ldquo;<a href="https://openreview.net/forum?id=qwULHx9zld">Random matrices in service of ML footprint: ternary random features with no performance loss</a>&rdquo;, <em>The Tenth International Conference on Learning Representations (<strong>ICLR 2022</strong>)</em>, 2022. <a href=https://arxiv.org/abs/2110.01899>preprint</a></p>
</li>
<li>
<p><strong>Z. Liao</strong>, M. W. Mahoney, &ldquo;<a href=https://papers.nips.cc/paper/2021/hash/a7d8ae4569120b5bec12e7b6e9648b86-Abstract.html>Hessian Eigenspectra of More Realistic Nonlinear Models</a>&rdquo; (<font color=red>Oral</font>), <em>The 35th Conference on Neural Information Processing Systems (<strong>NeurIPS 2021</strong>)</em>, 2021. <a href=https://arxiv.org/abs/2103.01519>preprint</a></p>
</li>
<li>
<p>M. Dereziński, <strong>Z. Liao</strong>, E. Dobriban, M. W. Mahoney, &ldquo;<a href=https://proceedings.mlr.press/v134/derezinski21a.html>Sparse sketches with small inversion bias</a>&rdquo;, <em>The 34th Annual Conference on Learning Theory (<strong>COLT 2021</strong>)</em>, 2021. <a href=https://arxiv.org/abs/2011.10695>preprint</a></p>
</li>
<li>
<p>F. Liu, <strong>Z.Liao</strong>, J. A.K. Suykens, &ldquo;<a href=http://proceedings.mlr.press/v130/liu21b.html>Kernel regression in high dimension: Refined analysis beyond double descent</a>&rdquo;, <em>The 24th International Conference on Artificial Intelligence and Statistics (<strong>AISTATS 2021</strong>)</em>, 2021. <a href=https://arxiv.org/abs/2010.02681>preprint</a></p>
</li>
<li>
<p><strong>Z.Liao</strong>, R. Couillet, M. W. Mahoney, &ldquo;<a href="https://openreview.net/forum?id=pBqLS-7KYAF">Sparse Quantized Spectral Clustering</a>&rdquo; (<font color=red>Spotlight</font>), <em>The Ninth International Conference on Learning Representations (<strong>ICLR 2021</strong>)</em>, 2021. <a href=../pdf/pre/iclr2021_poster.pdf>poster</a>, <a href=../pdf/pre/liao_iclr2021.pdf>slides</a>, and <a href=https://arxiv.org/abs/2010.01376>preprint</a></p>
</li>
<li>
<p><strong>Z.Liao</strong>, R. Couillet, M. W. Mahoney, &ldquo;<a href=https://papers.nips.cc/paper/2020/hash/a03fa30821986dff10fc66647c84c9c3-Abstract.html>A Random Matrix Analysis of Random Fourier Features: Beyond the Gaussian Kernel, A Precise Phase Transition, and the Corresponding Double Descent</a>&rdquo;, <em>The 34th Conference on Neural Information Processing Systems (<strong>NeurIPS 2020</strong>)</em>, Vancouver, Canada, 2020. <a href=../pdf/pre/liao_nips2020.pdf>poster</a> and <a href=https://arxiv.org/abs/2006.05013>preprint</a></p>
</li>
<li>
<p>M. Dereziński, F. Liang, <strong>Z. Liao</strong>, M. W. Mahoney, &ldquo;<a href=https://papers.nips.cc/paper/2020/hash/d40d35b3063c11244fbf38e9b55074be-Abstract.html>Precise expressions for random projections:
Low-rank approximation and randomized Newton</a>&rdquo;, <em>The 34th Conference on Neural Information Processing Systems (<strong>NeurIPS 2020</strong>)</em>, Vancouver, Canada, 2020. <a href=https://arxiv.org/abs/2006.10653>preprint</a></p>
</li>
<li>
<p><strong>Z.Liao</strong>, R. Couillet, &ldquo;<a href=https://ieeexplore.ieee.org/document/9022455>On Inner-product Kernels of High Dimensional Data</a>&rdquo;, <em>IEEE International Workshop on Computational Advances in Multi-Sensor Adaptive Processing (CAMSAP 2019)</em>, Guadeloupe, French West Indies, 2019. <a href=../pdf/conf/inner_prod_CAMSAP.pdf>preprint</a></p>
</li>
<li>
<p>X. Mai, <strong>Z. Liao</strong>, R. Couillet, &ldquo;<a href=https://ieeexplore.ieee.org/document/8683376>A Large Scale Analysis of Logistic Regression: Asymptotic Performance and New Insights</a>&rdquo;, <em>2019 IEEE International Conference on Acoustics, Speech and Signal Processing (<strong>ICASSP 2019</strong>)</em>, Brighton, UK, 2019. <a href=../pdf/pre/poster_ICASSP_LR.pdf>poster</a> and <a href=../pdf/conf/icassp_LR2018.pdf>preprint</a></p>
</li>
<li>
<p>R. Couillet, <strong>Z. Liao</strong>, X. Mai, &ldquo;<a href=https://ieeexplore.ieee.org/document/8553034>Classification Asymptotics in the Random Matrix Regime</a>&rdquo;, <em>The 26th European Signal Processing Conference (EUSIPCO 2018)</em>, Rome, Italy, 2018. <a href=../pdf/conf/eusipco_2018.pdf>preprint</a></p>
</li>
<li>
<p><strong>Z. Liao</strong>, R. Couillet, &ldquo;<a href=http://proceedings.mlr.press/v80/liao18a.html>On the Spectrum of Random Features Maps of High Dimensional Data</a>&rdquo;, <em>Proceedings of the 35th International Conference on Machine Learning (<strong>ICML 2018</strong>)</em>, Stockholm, Sweden, 2018. (<font color=red>Long Talk</font>) <a href=../pdf/pre/rfm_icml2018_pre.pdf>slides</a> and <a href=../pdf/conf/rfm_icml2018.pdf>preprint</a></p>
</li>
<li>
<p><strong>Z. Liao</strong>, R. Couillet, &ldquo;<a href=http://proceedings.mlr.press/v80/liao18b.html>The Dynamics of Learning: A Random Matrix Approach</a>&rdquo;, <em>Proceedings of the 35th International Conference on Machine Learning (<strong>ICML 2018</strong>)</em>, Stockholm, Sweden, 2018. (<font color=red>Long Talk</font>) <a href=../pdf/pre/gdd_icml2018_pre.pdf>slides</a> and <a href=../pdf/conf/gdd_icml2018.pdf>preprint</a></p>
</li>
<li>
<p><strong>Z. Liao</strong>, R. Couillet, &ldquo;<a href=https://ieeexplore.ieee.org/document/7952586/>Random Matrices Meet Machine Learning: A Large Dimensional Analysis of LS-SVM</a>&rdquo;, <em>2017 IEEE International Conference on Acoustics, Speech and Signal Processing (<strong>ICASSP 2017</strong>)</em>, New Orleans, USA, 2017. <a href=../pdf/pre/RMT4LSSVM-ICASSP-slides.pdf>slides</a> and <a href=../pdf/conf/RMT4LSSVM-ICASSP.pdf>preprint</a></p>
</li>
</ol>
<hr>
<h3 id=journals>Journals:</h3>
<ol>
<li>
<p>Z. Feng, Y. Wang, J. Li, F. Yang, J. Lou, T. Mi, R. C. Qiu, <strong>Z. Liao</strong>, &ldquo;<a href=https://ieeexplore.ieee.org/document/10772332>Robust and Communication-Efficient Federated Domain Adaptation via Random Features</a>&rdquo;, <em>IEEE Transactions on Knowledge and Data Engineering</em>, 2024. <a href=https://arxiv.org/abs/2311.04686>preprint</a> and <a href=https://github.com/SadAngelF/FedRF-TCA>code</a></p>
</li>
<li>
<p>J. Wang, S. Zhang, J. Cai, <strong>Z. Liao</strong>, C. Arenz, R. Betzholz, &ldquo;<a href=https://journals.aps.org/pra/abstract/10.1103/PhysRevA.108.022408>Robustness of random-control quantum-state tomography</a>&rdquo;, <em>Physical Review A</em> 108 (2 Aug. 2023), 022408. <a href=https://arxiv.org/abs/2302.07439>preprint</a></p>
</li>
<li>
<p>Y. Chitour, <strong>Z. Liao</strong>, R. Couillet, &ldquo;<a href=https://www.aimsciences.org/article/doi/10.3934/mcrf.2022021>A geometric approach of gradient descent algorithms in linear neural networks</a>&rdquo;, <em>Mathematical Control and Related Fields</em>, 13(3) (2023), 918–945. <a href=https://arxiv.org/abs/1811.03568>preprint</a></p>
</li>
<li>
<p><strong>Z.Liao</strong>, R. Couillet, M. W. Mahoney, &ldquo;<a href=https://iopscience.iop.org/article/10.1088/1742-5468/ac3a77>A random matrix analysis of random Fourier features: beyond the Gaussian kernel, a precise phase transition, and the corresponding double descent</a>&rdquo;, <em>Journal of Statistical Mechanics: Theory and Experiment</em> 2021(12) (Dec. 2021), 124006. <a href=https://arxiv.org/abs/2006.05013>preprint</a></p>
</li>
<li>
<p><strong>Z. Liao</strong>, R. Couillet, &ldquo;<a href=https://ieeexplore.ieee.org/document/8598904/>A Large Dimensional Analysis of Least Squares Support Vector Machines</a>&rdquo;, <em>IEEE Transactions on Signal Processing</em> 67 (4) (Feb. 2019), 1065-1074. (<font color=red>University of Paris-Saclay ED STIC Ph.D. Paper Award</font>) <a href=https://arxiv.org/abs/1701.02967>preprint</a> and <a href=../pdf/LSSVM-TSP-SM.pdf>supplementary material</a></p>
</li>
<li>
<p>C. Louart, <strong>Z. Liao</strong>, R. Couillet, &ldquo;<a href=https://projecteuclid.org/journals/annals-of-applied-probability/volume-28/issue-2/A-random-matrix-approach-to-neural-networks/10.1214/17-AAP1328.short>A Random Matrix Approach to Neural Networks</a>&rdquo;, <em>The Annals of Applied Probability</em> 28 (2) (Apr. 2018), 1190-1248. <a href=https://arxiv.org/abs/1702.05419>preprint</a></p>
</li>
</ol>
<hr>
<h3 id=preprints>Preprints:</h3>
<ul>
<li>
<p>Z. Wang, W. Yang, X. Mai, Z. Ling, <strong>Z. Liao</strong>, R. C. Qiu, &ldquo;<a href=https://arxiv.org/abs/2501.02746>A Large-dimensional Analysis of ESPRIT DoA Estimation: Inconsistency and a Correction via RMT</a>&rdquo;, 2025.</p>
</li>
<li>
<p>X. Mai, <strong>Z. Liao</strong>, &ldquo;<a href=https://arxiv.org/abs/2410.05609>The Breakdown of Gaussian Universality in Classification of High-dimensional Mixtures</a>&rdquo;, 2024.</p>
</li>
<li>
<p><strong>Z. Liao</strong>, Y. Xia, C. Niu, Y. Xiao, &ldquo;<a href=http://arxiv.org/abs/2306.08489>Analysis and Approximate Inference of Large Random Kronecker Graphs</a>&rdquo;, 2024.</p>
</li>
<li>
<p>Y. Du, Z. Ling, R. C. Qiu, <strong>Z. Liao</strong>, &ldquo;<a href=../pdf/conf/Dynamic_NTK_HiLD_2023.pdf>High-dimensional Learning Dynamics of Deep Neural Nets in the Neural Tangent Regime</a>&rdquo;, <em><a href=https://icml.cc/virtual/2023/workshop/21475>High-dimensional Learning Dynamics Workshop</a>, The Fortieth International Conference on Machine Learning</em>, 2023.</p>
</li>
<li>
<p>Z. Ling, <strong>Z. Liao</strong>, R. C. Qiu, &ldquo;<a href=../pdf/conf/Implicit_HiLD_2023.pdf>On the Equivalence Between Implicit and Explicit Neural Networks: A High-dimensional Viewpoint</a>&rdquo;, <em><a href=https://icml.cc/virtual/2023/workshop/21475>High-dimensional Learning Dynamics Workshop</a>, The Fortieth International Conference on Machine Learning</em>, 2023.</p>
</li>
<li>
<p>Y. Song, K. Wan, <strong>Z. Liao</strong>, G. Caire, &ldquo;<a href=https://arxiv.org/abs/2302.03549>An Achievable and Analytic Solution to Information Bottleneck for Gaussian Mixtures</a>&rdquo;, 2023.</p>
</li>
<li>
<p><strong>Z. Liao</strong>, R. Couillet, &ldquo;<a href=https://arxiv.org/abs/1909.06788>Inner-product Kernels are Asymptotically Equivalent to Binary Discrete Kernels</a>&rdquo;, 2019.</p>
</li>
<li>
<p>X. Mai, <strong>Z. Liao</strong>, &ldquo;<a href=https://arxiv.org/abs/1905.13742>High Dimensional Classification via Regularized and Unregularized Empirical Risk Minimization: Precise Error and Optimal Loss</a>&rdquo;, 2019.</p>
</li>
</ul>
<hr>
<h3 id=phd-thesis>Ph.D. thesis:</h3>
<p><strong>Z. Liao</strong>, &ldquo;<a href=https://tel.archives-ouvertes.fr/tel-02397287>A random matrix framework for large dimensional machine learning and neural networks</a>&rdquo;, <a href=http://www.centralesupelec.fr/en>CentraleSupélec</a>, <a href=https://www.universite-paris-saclay.fr/en>University Paris-Saclay</a>, September 2019. <a href=../pdf/PhD_defence_liao.pdf>[slides]</a></p>
</main>
<footer>
<script defer src=//zhenyu-liao.github.io/js/math-code.js></script>
<script defer src="//mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML"></script>
<script defer src=//zhenyu-liao.github.io/js/center-img.js></script>
<hr>
© <a href=https://zhenyu-liao.github.io/>Zhenyu Liao</a> 2016 &ndash; 2024 | <a href="https://scholar.google.fr/citations?user=SPYhJV8AAAAJ&hl=en">Google Scholar</a> | <a href=https://www.researchgate.net/profile/Zhenyu_Liao>Research Gate</a> | <a href=https://orcid.org/0000-0002-1915-8559>ORCID</a> | <a href=https://github.com/Zhenyu-LIAO/>Github</a> | <a href=https://zhuanlan.zhihu.com/RandomMatrixTheory>RMT on Zhihu</a>
</footer>
</body>
</html>