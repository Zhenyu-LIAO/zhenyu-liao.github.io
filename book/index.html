<!doctype html><html lang=en-us>
<head>
<meta charset=utf-8>
<meta name=viewport content="width=device-width,initial-scale=1">
<title>Book | Zhenyu Liao's Page</title>
<link rel=stylesheet href=/css/style.css>
<link rel=stylesheet href=/css/fonts.css>
</head>
<body>
<nav>
<ul class=menu>
<li><a href=/>Home</a></li>
<li><a href=/publications/>Publications</a></li>
<li><a href=/projects/>Projects</a></li>
<li><a href=/book/>Book</a></li>
<li><a href=/collaborators/>Collaborators</a></li>
<li><a href=/teaching/>Teaching</a></li>
<li><a href=/links/>Links</a></li>
<li><a href=/post_page/>Posts</a></li>
<li><a href=/index.xml>RSS subscribe</a></li>
</ul>
<hr>
</nav>
<div class=article-meta>
<h1><span class=title>Book</span></h1>
</div>
<main>
<img src=/img/RMT4ML_cover.jpg style="max-width:15%;min-width:75px;float:left;margin:5px 20px 5px 5px">
<h3 id=random-matrix-methods-for-machine-learning>Random Matrix Methods for Machine Learning</h3>
<p><a href=http://polaris.imag.fr/romain.couillet/index.html>Romain Couillet</a> and <a href=https://zhenyu-liao.github.io>Zhenyu Liao</a>, Cambridge University Press, 2022.</p>
<h4 id=online-ordering>Online Ordering:</h4>
<ul>
<li><a href=https://cambridge.org/9781009123235>Cambridge University Press</a></li>
<li><a href=https://www.amazon.com/Random-Matrix-Methods-Machine-Learning/dp/1009123238>Amazon</a></li>
</ul>
<h3 id=additional-resources-for-readers>Additional Resources for Readers</h3>
<p>A pre-production version of the book is available <a href=/pdf/RMT4ML.pdf>here</a>, with exercise solutions available <a href=/pdf/RMT4ML_solution.pdf>here</a>. <code>MATLAB</code> and <code>Python</code> codes to reproduce the figures in the book are publicly available in <a href=https://github.com/Zhenyu-LIAO/RMT4ML>this</a> repository.</p>
<p><strong>Disclaimer</strong>: The pre-publication version is free to view and download for personal use <strong>only</strong>, and is <strong>not</strong> for redistribution, re-sale or use in derivative works.</p>
<hr>
<h2 id=preface>Preface</h2>
<p>Numerous and large-dimensional data is now a default setting in modern machine learning (ML). Standard ML algorithms, starting with kernel methods such as support vector machines and graph-based methods like the PageRank algorithm, were however initially designed out of small-dimensional intuitions and tend to misbehave, if not completely collapse, when dealing with real-world large datasets. Random matrix theory has recently developed a broad spectrum of tools to help understand this new &ldquo;curse of dimensionality,&rdquo; to help repair or completely recreate the suboptimal algorithms, and most importantly, to provide new intuitions to deal with modern data mining. This book primarily aims to deliver these intuitions, by providing a digest of the recent theoretical and applied breakthroughs of random matrix theory into ML. Targeting a broad audience, spanning from undergraduate students interested in statistical learning to artificial intelligence engineers and researchers alike, the mathematical prerequisites to the book are minimal (basics of probability theory, linear algebra, and real and complex analyses are sufficient): As opposed to introductory books in the mathematical literature of random matrix theory and large-dimensional statistics, the theoretical focus here is restricted to the essential requirements to ML applications. These applications range from detection, statistical inference, and estimation to graph- and kernel-based supervised, semisupervised, and unsupervised classification, as well as neural networks: For these, a precise theoretical prediction of the algorithm performance (often inaccessible when not resorting to a random matrix analysis), large-dimensional insights, methods of improvement, along with a fundamental justification of the wide-scope applicability of the methods to real data, are provided. Most methods, algorithms, and figures proposed in the book are coded in <code>MATLAB</code> and <code>Python</code> and made available to the readers (<a href=https://github.com/Zhenyu-LIAO/RMT4ML>https://github.com/Zhenyu-LIAO/RMT4ML</a>). The book also contains a series of exercises of two types: short exercises with corrections available online to familiarize the reader with the basic theoretical notions and tools in random matrix analysis, as well as long guided exercises to apply these tools to further concrete ML applications.</p>
<hr>
<h4 id=readers-feedback>Reader&rsquo;s Feedback</h4>
<p>If you have any feedback, suggestions, or typos/errors to report, please contact us via email at <a href=mailto:romain.couillet@univ-grenoble-alpes.fr>romain.couillet@univ-grenoble-alpes.fr</a> and <a href=mailto:zhenyu_liao@hust.edu.cn>zhenyu_liao@hust.edu.cn</a>.</p>
<hr>
<h4 id=citing-the-book>Citing the book</h4>
<p>To cite this book, please consider using the following bibtex entry:</p>
<pre tabindex=0><code>@book{couillet_liao_2022, 
	place={Cambridge}, 
	title={Random Matrix Methods for Machine Learning}, 
	DOI={10.1017/9781009128490}, 
	publisher={Cambridge University Press}, 
	author={Couillet, Romain and Liao, Zhenyu}, 
	note={\url{https://zhenyu-liao.github.io/book/}},
	year={2022}
}
</code></pre><hr>
<h2 id=book-errata>Book errata</h2>
<p>Some corrections to typographical errors in the first edition of the book are listed <a href=/pdf/RMT4ML_erratum.pdf>here</a>.</p>
</main>
<footer>
<script defer src=//zhenyu-liao.github.io/js/math-code.js></script>
<script defer src="//mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML"></script>
<script defer src=//zhenyu-liao.github.io/js/center-img.js></script>
<hr>
Â© <a href=https://zhenyu-liao.github.io/>Zhenyu Liao</a> 2016 &ndash; 2024 | <a href="https://scholar.google.fr/citations?user=SPYhJV8AAAAJ&hl=en">Google Scholar</a> | <a href=https://www.researchgate.net/profile/Zhenyu_Liao>Research Gate</a> | <a href=https://orcid.org/0000-0002-1915-8559>ORCID</a> | <a href=https://github.com/Zhenyu-LIAO/>Github</a> | <a href=https://zhuanlan.zhihu.com/RandomMatrixTheory>RMT on Zhihu</a>
</footer>
</body>
</html>